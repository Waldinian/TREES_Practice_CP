class(TIMESTAMP)
All_Data.raw <- Combine(Combine(Combine(SoilHF.raw, Precip.raw), Met.raw), Flux.raw)
# Path to soils data and Precip data, stored on the UWyo PETA library
SoilHF.files <- Sys.glob(Sys.glob('/Volumes/TempData/Bretfeld\ Mario/Chimney/Data/BB-SF/SoilHF/2019*/*SoilData_BBSF*.dat'))
Precip.files <- Sys.glob(Sys.glob('/Volumes/TempData/Bretfeld\ Mario/Chimney/Data/BB-SF/SoilHF/2019*/*MetData_BBSF*.dat'))
Met.files <- Sys.glob(Sys.glob("/Volumes/TempData/Bretfeld\ Mario/Chimney/Data/BB-SF/EC/7m/2019*/Converted/TOA5_9810.Met30Min.dat"))
Flux.files <- Sys.glob(Sys.glob("AmeriFlux_CPk-BBSF-7m.csv"))  # this file can actually be used to get most of the necessary quantities
# given a list of file names, collect all the data from those files into one dataframe
Collect_Data <- function(.files){
# takes a list of file names and combines their contents into a single dataframe.
# also renames columns
# read in the first data file
# lines 1-4 contain header information, but only line 2 contains variable names
.raw <- read.csv(.files[1], skip=1, stringsAsFactors=FALSE, na = c("","NAN"))
for (fn in .files[-1]){
.f.raw <- read.csv(fn, skip=1, stringsAsFactors=FALSE, na = c("","NAN"))  # read the next data file
.raw <- rbind(.raw, .f.raw)  # add it onto the full data file
}
.raw <- .raw %>% mutate(TIMESTAMP = ymd_hms(TIMESTAMP))  # convert to ymd_hms format
.raw <- .raw[-which(is.na(.raw$TIMESTAMP)==TRUE), ]  # extraneous header lines have timestamp "NA," giving us a way to remove them
.raw <- .raw[!duplicated(.raw$TIMESTAMP), ]  # for some reason it imports each file like 12 times, so remove duplicate timestamps
# convert character vector columns to floats
.raw <- .raw %>%
mutate_at(names(.raw[-1]), as.numeric)
return(as_tibble(.raw))
}
# get data from files
SoilHF.raw <- Collect_Data(SoilHF.files)
Precip.raw <- Collect_Data(Precip.files)
Met.raw <- Collect_Data(Met.files[13:length(Met.files)])  # files have inconsistent variable names until the 13th file, so start there
# Ameriflux file needs to be handled slightly differently
Flux.raw <- read.csv(Flux.files, stringsAsFactors = FALSE, na = c("","NAN", "NaN", "-9999"))[-1, ] %>%  # import everything but the second header line
mutate(TIMESTAMP = ymd_hms(paste(substr(TIMESTAMP_START, 1, 4), "-",
substr(TIMESTAMP_START, 5, 6), "-",
substr(TIMESTAMP_START, 7, 8), " ",
substr(TIMESTAMP_START, 9, 10), ":",
substr(TIMESTAMP_START, 11, 12), ":",
"00",
sep = ""))) %>%  # convert from yyymmddhhmmss to yyyy-mm-dd hh:mm:ss format
mutate_at(names(Flux.raw[, -length(names(Flux.raw))]), as.numeric)  # convert everything but timestamp to numeric
# now merge them all together
Combine <- function(A.raw, B.raw){
full.raw.long <- full_join(by = "TIMESTAMP", A.raw, B.raw) # keep all values
}
All_Data.raw <- Combine(Combine(Combine(SoilHF.raw, Precip.raw), Met.raw), Flux.raw)
Flux.raw <- Collect_Data(Flux.files)
# Path to soils data and Precip data, stored on the UWyo PETA library
SoilHF.files <- Sys.glob(Sys.glob('/Volumes/TempData/Bretfeld\ Mario/Chimney/Data/BB-SF/SoilHF/2019*/*SoilData_BBSF*.dat'))
Precip.files <- Sys.glob(Sys.glob('/Volumes/TempData/Bretfeld\ Mario/Chimney/Data/BB-SF/SoilHF/2019*/*MetData_BBSF*.dat'))
Met.files <- Sys.glob(Sys.glob("/Volumes/TempData/Bretfeld\ Mario/Chimney/Data/BB-SF/EC/7m/2019*/Converted/TOA5_9810.Met30Min.dat"))
Flux.files <- Sys.glob(Sys.glob("AmeriFlux_CPk-BBSF-7m.csv"))  # this file can actually be used to get most of the necessary quantities
# Path to soils data and Precip data, stored on the UWyo PETA library
SoilHF.files <- Sys.glob(Sys.glob('/Volumes/TempData/Bretfeld\ Mario/Chimney/Data/BB-SF/SoilHF/2019*/*SoilData_BBSF*.dat'))
Precip.files <- Sys.glob(Sys.glob('/Volumes/TempData/Bretfeld\ Mario/Chimney/Data/BB-SF/SoilHF/2019*/*MetData_BBSF*.dat'))
Met.files <- Sys.glob(Sys.glob("/Volumes/TempData/Bretfeld\ Mario/Chimney/Data/BB-SF/EC/7m/2019*/Converted/TOA5_9810.Met30Min.dat"))
Flux.files <- Sys.glob(Sys.glob("AmeriFlux_CPk-BBSF-7m.csv"))  # this file can actually be used to get most of the necessary quantities
# given a list of file names, collect all the data from those files into one dataframe
Collect_Data <- function(.files){
# takes a list of file names and combines their contents into a single dataframe.
# also renames columns
# read in the first data file
# lines 1-4 contain header information, but only line 2 contains variable names
.raw <- read.csv(.files[1], skip=1, stringsAsFactors=FALSE, na = c("","NAN"))
for (fn in .files[-1]){
.f.raw <- read.csv(fn, skip=1, stringsAsFactors=FALSE, na = c("","NAN"))  # read the next data file
.raw <- rbind(.raw, .f.raw)  # add it onto the full data file
}
.raw <- .raw %>% mutate(TIMESTAMP = ymd_hms(TIMESTAMP))  # convert to ymd_hms format
.raw <- .raw[-which(is.na(.raw$TIMESTAMP)==TRUE), ]  # extraneous header lines have timestamp "NA," giving us a way to remove them
.raw <- .raw[!duplicated(.raw$TIMESTAMP), ]  # for some reason it imports each file like 12 times, so remove duplicate timestamps
# convert character vector columns to floats
.raw <- .raw %>%
mutate_at(names(.raw[-1]), as.numeric)
return(as_tibble(.raw))
}
# get data from files
SoilHF.raw <- Collect_Data(SoilHF.files)
Precip.raw <- Collect_Data(Precip.files)
Met.raw <- Collect_Data(Met.files[13:length(Met.files)])  # files have inconsistent variable names until the 13th file, so start there
# Ameriflux file needs to be handled slightly differently
Flux.raw <- read.csv(Flux.files, stringsAsFactors = FALSE, na = c("","NAN", "NaN", "-9999"))[-1, ] %>%  # import everything but the second header line
mutate(TIMESTAMP = ymd_hms(paste(substr(TIMESTAMP_START, 1, 4), "-",
substr(TIMESTAMP_START, 5, 6), "-",
substr(TIMESTAMP_START, 7, 8), " ",
substr(TIMESTAMP_START, 9, 10), ":",
substr(TIMESTAMP_START, 11, 12), ":",
"00",
sep = ""))) %>%  # convert from yyymmddhhmmss to yyyy-mm-dd hh:mm:ss format
mutate_at(names(Flux.raw[, -length(names(Flux.raw))]), as.numeric)  # convert everything but timestamp to numeric
# Ameriflux file needs to be handled slightly differently
Flux.raw <- read.csv(Flux.files, stringsAsFactors = FALSE, na = c("","NAN", "NaN", "-9999"))[-1, ] %>%  # import everything but the second header line
mutate(TIMESTAMP = ymd_hms(paste(substr(TIMESTAMP_START, 1, 4), "-",
substr(TIMESTAMP_START, 5, 6), "-",
substr(TIMESTAMP_START, 7, 8), " ",
substr(TIMESTAMP_START, 9, 10), ":",
substr(TIMESTAMP_START, 11, 12), ":",
"00",
sep = "")))  # convert from yyymmddhhmmss to yyyy-mm-dd hh:mm:ss format
Flux.raw <- Flux.raw %>%
mutate_at(names(Flux.raw[, -length(names(Flux.raw))]), as.numeric)  # convert everything but timestamp to numeric
# now merge them all together
Combine <- function(A.raw, B.raw){
full.raw.long <- full_join(by = "TIMESTAMP", A.raw, B.raw) # keep all values
}
All_Data.raw <- Combine(Combine(Combine(SoilHF.raw, Precip.raw), Met.raw), Flux.raw)
# Take columns from All_Data.raw and put them into individual vectors
Year = year(All_Data.raw$TIMESTAMP)
DOY = yday(All_Data.raw$TIMESTAMP)
TIMESTAMP = All_Data.raw$TIMESTAMP
AirTemp_C <- All_Data.raw$T_SONIC_1_1_1
AirTemp.Plot <- ggplot() +
geom_line(mapping = aes(x=TIMESTAMP, y=AirTemp_C))
RH_fraction <- All_Data.raw$RH_1_1_1/100
Vap_Press_kPa <- RH_fraction*0.6108*exp(17.27*T/(T + 237.3))
Vap_Press.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=Vap_Press_kPa), size = 0.1)
Qpar <- All_Data.raw$PPFD_IN  # incoming PAR
Qpar.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP %>% filter(hour(TIMESTAMP)==12), y=All_Data.raw$PPFD_IN %>% filter(hour(TIMESTAMP)==12)), size=0.1)
Qpar.Plot
Qpar.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=Qpar), size=0.1)
Qpar.Plot
WindSpeed_m_s <- All_Data.raw$WS_1_1_1
WS.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=WindSpeed_m_s), size = 0.1)
WindDir_Deg <- All_Data.raw$WD_1_1_1
WD.Plot <- ggplot() +
geom_point(aes(x = WindSpeed_m_s, y = WindDir_Deg, color = hour(TIMESTAMP)), size = 0.8, alpha = 0.05) +
coord_polar(theta = "y") +
scale_color_continuous(low="blue", high="red")
WD.Plot  # very cool plot
Rain_Tot <- All_Data.raw$Rain_mm_Tot
SoilTemp_5cm_C <- All_Data.raw %>%
pivot_longer(-TIMESTAMP, names_to = "pit", values_to = "temp") %>%  # longify
filter(pit == "SoilT_PitA_5_Avg" |
pit == "SoilT_PitB_5_Avg" |
pit == "SoilT_PitC_5_Avg" |
pit == "SoilT_PitD_5_Avg") %>%   # want the 5cm soil pits
group_by(TIMESTAMP) %>%  # group by timestamp so that we can average all four soil pits in one timestamp
summarize(temp = mean(temp, na.rm = TRUE))  # take the mean of all four soil pits at one timestamp
SoilTemp_5cm_C <- SoilTemp_5cm_C$temp
Soil5.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=SoilTemp_5cm_C), size = 0.1)
SoilTemp_15cm_C <- All_Data.raw %>%
pivot_longer(-TIMESTAMP, names_to = "pit", values_to = "temp") %>%
filter(pit == "SoilT_PitA_15_Avg" |
pit == "SoilT_PitB_15_Avg" |
pit == "SoilT_PitC_15_Avg" |
pit == "SoilT_PitD_15_Avg") %>%  # want the 15cm pits
group_by(TIMESTAMP) %>%  #same as above chunk
summarize(temp = mean(temp, na.rm = TRUE))  # same as above chunk
SoilTemp_15cm_C <-  SoilTemp_15cm_C$temp
Soil15.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=SoilTemp_15cm_C), size = 0.1)
BaPress_kPa <- All_Data.raw$PA_1_1_1
BaPress.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=BaPress_kPa))
CO2_atm <- All_Data.raw$CO2_1_1_1
CO2.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=CO2_atm))
T_canopy <- All_Data.raw$T_CANOPY_1_1_1
T_can.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=T_canopy))
# write all the columns into one "weather" dataframe
weather <- data.frame(Year, DOY, TIMESTAMP, AirTemp_C, RH_fraction, Vap_Press_kPa, Qpar, WindSpeed_m_s, WindDir_Deg, Rain_Tot, SoilTemp_5cm_C, SoilTemp_15cm_C, BaPress_kPa, CO2_atm, T_canopy)
#TREES dates appear as YEARDAY, e.g. 2021001 for January 1, 2021
weather$date <- weather$Year*1000 + weather$DOY
nrows <- length(weather$date)
treesMet <- array(data=0,dim=c(nrows,18))  # create an empty array
colnames(treesMet)<-c("Date","Time","u_ref","t_ref","d_ref","precip","Qpar","t_canopy","d_canopy",
"p_atm","CO2_atm","Ts0","Tsurf","Troot","Zw","xylemScalar","NEEobs","Ec")  # give it these column names
treesMet <- as_tibble(treesMet)  # make it a tibble. I don't really know what an array is, except that it doesn't work with the below code
# define all the columns in the driver file
treesMet <- treesMet %>%
mutate(Date = weather$date,
Time = hour(weather$TIMESTAMP) + minute(weather$TIMESTAMP)/60,
u_ref = if_else(weather$WindSpeed_m_s < 0.01, 0.01, weather$WindSpeed_m_s),  # lower limit of 0.01 m/s
t_ref = weather$AirTemp_C,
d_ref = (1 - weather$RH_fraction)*0.61094*exp(17.625*t_ref/(t_ref+243.04)),  # saturation vapor pressure
precip = weather$Rain_Tot,
Qpar = weather$Qpar,
t_canopy = weather$T_canopy,
d_canopy = (1 - weather$RH_fraction)*0.61094*exp(17.625*t_canopy/(t_canopy + 243.04)),  # same
p_atm = weather$BaPress_kPa,
CO2_atm = weather$CO2_atm,
Ts0 = 0.5*(weather$SoilTemp_5cm_C + t_canopy),  # don't have soil surface, so use an average of 5cm and air
Tsurf = weather$SoilTemp_5cm_C,
Troot = weather$SoilTemp_15cm_C,
Zw = -10,  # unreachable water table
xylemScalar = 1,  # can be used to manipulate hydraulics. Default 1. 0.99 resets min. xylem pressures to sol water pressurem and remove memory of past droughts
NEEobs = -999,  # legacy column for use with MCMC algorithm
Ec = -999  # same
)
treesMet[treesMet == "NaN"] <- NA  # don't know what those "NaN" strings are there from.
treesMet <- treesMet %>%
filter(Date > 2019211 & Date < 2019246)  # dates with good chunks of continuous data
CO2_na <- which(is.na(treesMet$CO2_atm))  # to check later, to make sure that it worked
Date_na <- which(is.na(treesMet$Date))  # if this has NAs, you have a problem
Time_na <- which(is.na(treesMet$Time))  # if this has NAs you have a problem
if(length(Date_na) + length(Time_na) != 0) print("You have NAs in your time columns, stopping program...")
stopifnot(length(Date_na) + length(Time_na) == 0)
for (col in 1:length(treesMet)){  # loop over columns
for (row in 1:length(treesMet[[col]])){  # loop over rows
if (is.na(treesMet[row, col])){  # detect an NA
last_finite <-  row - 1  # grab the index of the previous entry, which should be finite.
next_finite <- row  # we'll be looping over this in the while loop below
reached_end <- FALSE  # for the edge case where we reach the end without finding a finite element.
while (is.na(treesMet[next_finite, col])){  # check to see if the current element is an NA
if (next_finite == length(treesMet[[col]])){
reached_end <- TRUE
break  # if we've reached the end of the list, exit the loop
}
next_finite <- next_finite + 1  # if it is, check the next element. Otherwise, exit the loop
}
if (reached_end == TRUE){  # edge case (see above)
gap_fill <- treesMet[last_finite, col]  # fill using the last finite element
for(na_index in (last_finite + 1):length(tressMet[[col]])) treesMet[na_index, col] <- gap_fill
}
else{  # not an edge case, and there is next finite element
gap_fill <- 0.5*(treesMet[last_finite, col] + treesMet[next_finite, col])  # take the average of the last and next finite numbers
for(na_index in (last_finite + 1):(next_finite - 1)) treesMet[na_index, col] <- gap_fill
}
}
}
}
write_delim(treesMet, "treesMet_BBSF_2019212_2019245.txt", delim = "\t")
ggplot(data = treesMet) +
geom_point(aes(x=Time, y=Qpar), size=0.3)  # compress all data into one day and plot, choose your favorite variable
##set working directory to where you downloaded off of github. Example if you downloaded it to your desktop:
setwd(paste("~/Work/UWyo/2021 Spring/TREES Workshops/",sep=""))
#Run these two lines after setting your working directory.
source("easyR_TREES/Functions_easyR_TREES.R")
source("easyR_TREES/Graph_easyR_TREES.R")
Dest <- "Examples/BBSF_Test/Outputs"
Driver <- "treesMet_BBSF_2019212_2019245"
#Run the TREES model with specified parameters. See argument comments for explanations.
Run_easyR_TREES(Result_Dest=Dest,#Your destination for TREES outputs.
Init_param="Examples/BBSF_Test/pinus_edulis_dead.p",#Name and location of initial parameter file (.p)
Which_Parameter="microbiomeScalar",#Parameter to modify (MUST MATCH PARAMETER NAME IN .p file exactly).
New_values=c(100,200,250,300,500), #A vector of the new values for the specified parameter.
Use_Gamma=FALSE,#T or F use the growth gamma function.
Itter=NULL,#Number of iterations for running over the gamma.
Drivers=Driver,#Vector of names of drivers to use.
Driver_loc="Examples/BBSF_Test",#Location of drivers if not in working directory.
Init_Infile="Examples/BBSF_Test/inBBSF_dead",#Name and location of initial infile to be modified.
param_mod = "Examples/BBSF_Test/pine_mod",#Name and location of param_mod file.
covfile="Examples/BBSF_Test/covfile1",#Name and location of covfile.
N_cores=1,#Number of cores to use for parallel runs. WARNING! This should be at least 1 less than total cores
TREES_loc="Model-Code/trees3",#Location of *compiled* TREES model.
show_TREES_cout=TRUE#FALSE will hide the trees console readout.
)
#Generate plots of the leaf areas
Leaf_Area_Plot(Result_Dest=Dest,#Location you set for TREES outputs.
Which_Parameter="microbiomeScalar",#Parameter that was modified.
New_values=c(100,200,250,300,500),#Values parameter was changed to.
Use_Gamma=FALSE,#Set to TRUE if Gamma was used.
Itter=NULL,#Number of ittereations if Gamma was used.
Drivers=Driver,#Vector of the drivers used.
Figure_title=NULL,#Optional title for graphs.
Compare_to=NULL,#Optional data.frame of experimental data to compare to.
Smooth_on=FALSE#False will create a boxplot at each day and smooth will create a smooth line with geom_smooth
##(only applies to exp data or if gamma was on)
)
#Generate plots of
Sim_Plot(Result_Dest=Dest,
Which_Sim = "R_total",#Name of the column in the .sim file that you wish to plot (must match exactly).
Which_Parameter="microbiomeScalar",
New_values=c(100,200,250,300,500),
Use_Gamma=FALSE,
Itter=NULL,
Drivers=Driver,
Figure_title=NULL,
Compare_to=NULL,
Smooth_on=TRUE
)
library(ggplot2)
library(tidyverse)
library(lubridate)
setwd("~/Work/UWyo/2021 Spring/TREES Workshops/Examples/BBSF_Test/")
library(ggplot2)
library(tidyverse)
library(lubridate)
setwd("~/Work/UWyo/2021 Spring/TREES Workshops/Examples/BBSF_Test/")
df <- read.csv("Outputs/microbiomeScalar/BBSF_Dead.sim/microbiomeScalar100itter0.sim", sep = "\t")
df <- read.csv("Outputs/microbiomeScalar/treesMet_BBSF_2019212_2019245/microbiomeScalar100itter0.sim", sep = "\t")
View(df)
setwd("~/Work/UWyo/2021 Spring/TREES Workshops/Examples/BBSF_Test/")
df <- read.csv("Outputs/microbiomeScalar/treesMet_BBSF_2019212_2019245/microbiomeScalar100itter0.sim", sep = "\t")
View(df)
yday("2012-03-12")
as.Date(104, origin = "2014-01-01")
df <- read.csv("Outputs/microbiomeScalar/treesMet_BBSF_2019212_2019245/microbiomeScalar100itter0.sim", sep = "\t") %>%
ggplot(data=df) +
geom_point(aes(y=simET))
df <- read.csv("Outputs/microbiomeScalar/treesMet_BBSF_2019212_2019245/microbiomeScalar100itter0.sim", sep = "\t") %>%
plot(df$simET)
df <- read.csv("Outputs/microbiomeScalar/treesMet_BBSF_2019212_2019245/microbiomeScalar100itter0.sim", sep = "\t") %>%
plot(df$simET)
par(mar)
par("mar")
par(mar=c(1,1,1,1))
df <- read.csv("Outputs/microbiomeScalar/treesMet_BBSF_2019212_2019245/microbiomeScalar100itter0.sim", sep = "\t") %>%
plot(df$simET)
par("mar")
df <- read.csv("Outputs/microbiomeScalar/treesMet_BBSF_2019212_2019245/microbiomeScalar100itter0.sim", sep = "\t") %>%
mutate(index = 0)
for (i in 1:length(df)) df$index[i] <- i
df <- read.csv("Outputs/microbiomeScalar/treesMet_BBSF_2019212_2019245/microbiomeScalar100itter0.sim", sep = "\t") %>%
mutate(index = 0)
df$index
for (i in 1:length(df)) df$index[i] <- i
df$index
for (i in 1:length(df)){
df$index[i] <- i
print(df$index[i])}
df$index
for (i in 1:length(df)){
df$index[[i]] <- i
print(df$index[i])}
df$index
for (i in 1:length(df[[1]])){
df$index[[i]] <- i
print(df$index[i])}
df[[1]]
df$index
for (i in 1:length(df[[1]])){
df$index[i] <- i
}
df$index
ggplot(data=df)+
geom_point(aes(x=index,y=simET))
ggplot(data=df)+
geom_point(aes(x=index,y=NEE))
ggplot(data=df)+
geom_point(aes(x=index,y=NEE))+
ylim(0,250)
ggplot(data=df)+
geom_point(aes(x=index,y=NEE))+
ylim(0,10)
ggplot(data=df)+
geom_point(aes(x=index,y=NEE))+
ylim(0,30)
ggplot(data=df)+
geom_line(aes(x=index,y=NEE))+
ylim(0,30)
ggplot(data=df)+
geom_line(aes(x=index,y=NEE))+
ylim(0,20)
ggplot(data=df)+
geom_line(aes(x=index,y=simET), size=0.3)
ggplot(data=df)+
geom_line(aes(x=index,y=simET), size=0.3)
ggplot(data=df)+
geom_line(aes(x=index,y=NEE), size=0.3)+
ylim(0,20)
ggplot(data=df)+
geom_line(aes(x=index,y=NEE), size=0.3)
ggplot(data=df)+
geom_line(aes(x=index,y=NEE), size=0.3)+
ylim(0,20)
ggplot(data=df)+
geom_line(aes(x=index,y=NEE), size=0.3)+
ylim(0,20)
ggplot(data=df)+
geom_line(aes(x=index,y=NEE), size=0.3)
ggplot(data=df)+
geom_line(aes(x=index,y=NEE), size=0.3)+
ylim(0,20)
library(tidyverse)
library(ggplot2)
library(lubridate)
setwd("~/Work/UWyo/2021 Spring/TREES Workshops/Examples/BBSF_Test/")
# AmeriFlux variable names:
# https://ameriflux.lbl.gov/data/aboutdata/data-variables/
#
# Variables of interest: (Ameriflux -> TREES)
# TIMESTAMP_START -> Year
# TIMESTAMP_START -> DOY
# TIMESTAMP_START -> TIMESTAMP
# T_SONIC_1_1_1 -> AirTemp_C
# RH_1_1_1 -> RH_fraction
# RH_1_1_1 -> Vap_Press_kPa
# From Met file -> Qpar
# WS_1_1_1 -> WindSpeed_m_s
# WD_1_1_1 -> WindDir_Deg
# From precip file -> Rain_Tot
# From soil file -> SoilTemp_5cm_C
# From soil file -> SoilTemp_15cm_C
# PA_1_1_1 -> BaPress_kPa
# CO2_1_1_1 -> CO2_atm
#################################################
# This Part of the Program aggregates the data. #
#################################################
# Path to soils data and Precip data, stored on the UWyo PETA library
SoilHF.files <- Sys.glob(Sys.glob('/Volumes/TempData/Bretfeld\ Mario/Chimney/Data/BB-SF/SoilHF/2019*/*SoilData_BBSF*.dat'))
Precip.files <- Sys.glob(Sys.glob('/Volumes/TempData/Bretfeld\ Mario/Chimney/Data/BB-SF/SoilHF/2019*/*MetData_BBSF*.dat'))
Met.files <- Sys.glob(Sys.glob("/Volumes/TempData/Bretfeld\ Mario/Chimney/Data/BB-SF/EC/7m/2019*/Converted/TOA5_9810.Met30Min.dat"))
Flux.files <- Sys.glob(Sys.glob("AmeriFlux_CPk-BBSF-7m.csv"))  # this file can actually be used to get most of the necessary quantities
# given a list of file names, collect all the data from those files into one dataframe
Collect_Data <- function(.files){
# takes a list of file names and combines their contents into a single dataframe.
# also renames columns
# read in the first data file
# lines 1-4 contain header information, but only line 2 contains variable names
.raw <- read.csv(.files[1], skip=1, stringsAsFactors=FALSE, na = c("","NAN"))
for (fn in .files[-1]){
.f.raw <- read.csv(fn, skip=1, stringsAsFactors=FALSE, na = c("","NAN"))  # read the next data file
.raw <- rbind(.raw, .f.raw)  # add it onto the full data file
}
.raw <- .raw %>% mutate(TIMESTAMP = ymd_hms(TIMESTAMP))  # convert to ymd_hms format
.raw <- .raw[-which(is.na(.raw$TIMESTAMP)==TRUE), ]  # extraneous header lines have timestamp "NA," giving us a way to remove them
.raw <- .raw[!duplicated(.raw$TIMESTAMP), ]  # for some reason it imports each file like 12 times, so remove duplicate timestamps
# convert character vector columns to floats
.raw <- .raw %>%
mutate_at(names(.raw[-1]), as.numeric)
return(as_tibble(.raw))
}
# get data from files
SoilHF.raw <- Collect_Data(SoilHF.files)
Precip.raw <- Collect_Data(Precip.files)
Met.raw <- Collect_Data(Met.files[13:length(Met.files)])  # files have inconsistent variable names until the 13th file, so start there
# Ameriflux file needs to be handled slightly differently
Flux.raw <- read.csv(Flux.files, stringsAsFactors = FALSE, na = c("","NAN", "NaN", "-9999"))[-1, ] %>%  # import everything but the second header line
mutate(TIMESTAMP = ymd_hms(paste(substr(TIMESTAMP_START, 1, 4), "-",
substr(TIMESTAMP_START, 5, 6), "-",
substr(TIMESTAMP_START, 7, 8), " ",
substr(TIMESTAMP_START, 9, 10), ":",
substr(TIMESTAMP_START, 11, 12), ":",
"00",
sep = "")))  # convert from yyymmddhhmmss to yyyy-mm-dd hh:mm:ss format
Flux.raw <- Flux.raw %>%
mutate_at(names(Flux.raw[, -length(names(Flux.raw))]), as.numeric)  # convert everything but timestamp to numeric
# now merge them all together
Combine <- function(A.raw, B.raw){
full.raw.long <- full_join(by = "TIMESTAMP", A.raw, B.raw) # keep all values
}
All_Data.raw <- Combine(Combine(Combine(SoilHF.raw, Precip.raw), Met.raw), Flux.raw)
# test plots for QA/QC
SoilTest.Plot <- ggplot(data = All_Data.raw, size=0.01) +
geom_line(mapping = aes(x=TIMESTAMP, y=SoilT_PitA_5_Avg,), color='blue')+
geom_line(mapping = aes(x=TIMESTAMP, y=SoilT_PitA_15_Avg), color='red')
# SoilTest.Plot
PrecipTest.Plot <- ggplot(data = All_Data.raw)+
geom_col(mapping=aes(x=TIMESTAMP, y=Rain_mm_Tot))
# PrecipTest.Plot
MetTest.Plot <- ggplot(data = All_Data.raw)+
geom_point(mapping = aes(x=TIMESTAMP, y=AirT_6m_Avg), size = 0.5)
# MetTest.Plot
CO2Test.Plot <- ggplot(data = All_Data.raw)+
geom_point(mapping = aes(x=TIMESTAMP, y=CO2_1_1_1), size = 0.5)
# CO2Test.Plot
write.csv(All_Data.raw, "BBSF_2019_All_Weather.csv")
####################################################################################################
# Comments:
# * there's a day in april or may with a massive (erroneous) spike in precip
# * probably because of melt.
# * only look at precip data after spring melt.
# * need to start in may anyway, because that's when the met data starts
# * looks like the IRGA was calibrated in july 2019 and december 2018, but I'll deal with that later
#####################################################################################################
# To create the driver file, I'm going to duplicate the weather2013part.csv format,
# then feed that file into the create_driver_file.R script
# in writing this code, I realized that there are several things that I really didn't need to do,
# but they don't really screw anything up, so if anything seems redudant here, that's because it is.
# Take columns from All_Data.raw and put them into individual vectors
Year = year(All_Data.raw$TIMESTAMP)
DOY = yday(All_Data.raw$TIMESTAMP)
TIMESTAMP = All_Data.raw$TIMESTAMP
AirTemp_C <- All_Data.raw$T_SONIC_1_1_1
AirTemp.Plot <- ggplot() +
geom_line(mapping = aes(x=TIMESTAMP, y=AirTemp_C))
#AirTemp.Plot
RH_fraction <- All_Data.raw$RH_1_1_1/100
Vap_Press_kPa <- RH_fraction*0.6108*exp(17.27*T/(T + 237.3))
Vap_Press.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=Vap_Press_kPa), size = 0.1)
# Vap_Press.Plot
Qpar <- All_Data.raw$PPFD_IN  # incoming PAR
Qpar.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=Qpar), size=0.1)
Qpar.Plot
WindSpeed_m_s <- All_Data.raw$WS_1_1_1
WS.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=WindSpeed_m_s), size = 0.1)
# WS.Plot
WindDir_Deg <- All_Data.raw$WD_1_1_1
WD.Plot <- ggplot() +
geom_point(aes(x = WindSpeed_m_s, y = WindDir_Deg, color = hour(TIMESTAMP)), size = 0.8, alpha = 0.05) +
coord_polar(theta = "y") +
scale_color_continuous(low="blue", high="red")
WD.Plot  # very cool plot
Rain_Tot <- All_Data.raw$Rain_mm_Tot
SoilTemp_5cm_C <- All_Data.raw %>%
pivot_longer(-TIMESTAMP, names_to = "pit", values_to = "temp") %>%  # longify
filter(pit == "SoilT_PitA_5_Avg" |
pit == "SoilT_PitB_5_Avg" |
pit == "SoilT_PitC_5_Avg" |
pit == "SoilT_PitD_5_Avg") %>%   # want the 5cm soil pits
group_by(TIMESTAMP) %>%  # group by timestamp so that we can average all four soil pits in one timestamp
summarize(temp = mean(temp, na.rm = TRUE))  # take the mean of all four soil pits at one timestamp
SoilTemp_5cm_C <- SoilTemp_5cm_C$temp
Soil5.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=SoilTemp_5cm_C), size = 0.1)
# Soil5.Plot
SoilTemp_15cm_C <- All_Data.raw %>%
pivot_longer(-TIMESTAMP, names_to = "pit", values_to = "temp") %>%
filter(pit == "SoilT_PitA_15_Avg" |
pit == "SoilT_PitB_15_Avg" |
pit == "SoilT_PitC_15_Avg" |
pit == "SoilT_PitD_15_Avg") %>%  # want the 15cm pits
group_by(TIMESTAMP) %>%  #same as above chunk
summarize(temp = mean(temp, na.rm = TRUE))  # same as above chunk
SoilTemp_15cm_C <-  SoilTemp_15cm_C$temp
Soil15.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=SoilTemp_15cm_C), size = 0.1)
# Soil15.Plot
BaPress_kPa <- All_Data.raw$PA_1_1_1
BaPress.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=BaPress_kPa))
# BaPress.Plot
CO2_atm <- All_Data.raw$CO2_1_1_1
CO2.Plot <- ggplot() + geom_point(aes(x=TIMESTAMP, y=CO2_atm))
# CO2.Plot
CO2.Plot
ggplot(data=df)+
geom_line(aes(x=index,y=Asun))
